{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89eb636",
   "metadata": {},
   "source": [
    "Notebook for experimenting with what's implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0074443",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddca0a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "de_en_tokenizer = Tokenizer.from_file(\"tokenizers/de_en_tokenizer.json\")\n",
    "\n",
    "de_en_tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "151544ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_en_tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63fe37d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dataloader called\n",
      "Bos token:  1\n",
      "EOS token:  2\n",
      "Tokenizing dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f09599855bd4ac2b958369e015a64e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing dataset:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess function called for:  {'translation': [{'de': 'Guten morgen.', 'en': 'Good morning.'}, {'de': 'Guten tag.', 'en': 'Good day.'}, {'de': 'Wilkommen.', 'en': 'Welcome.'}, {'de': 'Wie geht es Ihnen?', 'en': 'How are you?'}, {'de': 'Das ist ein Buch.', 'en': 'That is a book.'}, {'de': 'Ich denke, dass ich einen Kaffee brauche.', 'en': 'I think I need a coffee.'}, {'de': 'Ich bin ein bisschen m dde.', 'en': 'I am a bit tired.'}]}\n",
      "Dataset tokenized\n",
      "Sampler initialized\n",
      "Dataloader initialized\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from datasets import Dataset\n",
    "import dnlp2025.dataset  # your local module\n",
    "importlib.reload(dnlp2025)\n",
    "\n",
    "def get_mock_split_small():\n",
    "    return Dataset.from_list([\n",
    "        { \"translation\": { \"de\": \"Guten morgen.\", \"en\": \"Good morning.\" }},\n",
    "        { \"translation\": { \"de\": \"Guten tag.\", \"en\": \"Good day.\" }},\n",
    "        { \"translation\": { \"de\": \"Wilkommen.\", \"en\": \"Welcome.\" }},\n",
    "        { \"translation\": { \"de\": \"Wie geht es Ihnen?\", \"en\": \"How are you?\" }},\n",
    "        { \"translation\": { \"de\": \"Das ist ein Buch.\", \"en\": \"That is a book.\" }},\n",
    "        { \"translation\": { \"de\": \"Ich denke, dass ich einen Kaffee brauche.\", \"en\": \"I think I need a coffee.\" }},\n",
    "        { \"translation\": { \"de\": \"Ich bin ein bisschen m dde.\", \"en\": \"I am a bit tired.\" }}\n",
    "    ])\n",
    "\n",
    "mock_split = Dataset.from_list(get_mock_split_small())\n",
    "\n",
    "de_en_train_dataloader = dnlp2025.dataset.create_dataloader(\n",
    "    mock_split,\n",
    "    \"test\", # If set to \"train\", then the last batch will be removed\n",
    "    de_en_tokenizer,\n",
    "    max_tokens_per_batch=20,\n",
    "    shuffle=False # Shuffling disabled to see how the batches are created\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b8d4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special token ids: Padding - 0, EOS - 1, BOS - 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch:  1\n",
      "Encoder input ids: \n",
      "tensor([[    1, 14070,    16,     2,     0,     0],\n",
      "        [    1, 12492, 10038,    16,     2,     0],\n",
      "        [    1, 12492,  4328,    16,     2,     0],\n",
      "        [    1,  7815,  3862,  3974,    33,     2]])\n",
      "\n",
      "Decoder input ids (should strip EOS token): \n",
      "tensor([[    1, 12905,  4391,    16,     0,     0],\n",
      "        [    1,    41,  5289,  9304,    16,     0],\n",
      "        [    1,    41,  5289,  6169,    16,     0],\n",
      "        [    1,  5118,  5255,  3769,  4755,    33]])\n",
      "\n",
      "Label ids (should strip BOS token): \n",
      "tensor([[12905,  4391,    16,     2,     0,     0],\n",
      "        [   41,  5289,  9304,    16,     2,     0],\n",
      "        [   41,  5289,  6169,    16,     2,     0],\n",
      "        [ 5118,  5255,  3769,  4755,    33,     2]])\n",
      "\n",
      "Batch:  2\n",
      "Encoder input ids: \n",
      "tensor([[    1,  5336,  3772,    67,  5689,    16,     2,     0],\n",
      "        [    1,    43,  3811,    67,  5760, 28026,    16,     2]])\n",
      "\n",
      "Decoder input ids (should strip EOS token): \n",
      "tensor([[    1,  4151,  3831,  3791,  7057,    16,     0,     0,     0],\n",
      "        [    1,  4191,  4681,  3791, 21375,    79,    70,  3795,    16]])\n",
      "\n",
      "Label ids (should strip BOS token): \n",
      "tensor([[ 4151,  3831,  3791,  7057,    16,     2,     0,     0,     0],\n",
      "        [ 4191,  4681,  3791, 21375,    79,    70,  3795,    16,     2]])\n",
      "\n",
      "Batch:  3\n",
      "Encoder input ids: \n",
      "tensor([[    1,    43,  5351,    43,  4413,    67, 11480,    16,     2]])\n",
      "\n",
      "Decoder input ids (should strip EOS token): \n",
      "tensor([[    1,  4191,  8001,    14,  3963,  3783,  4043, 15463,  4835,    71,\n",
      "            16]])\n",
      "\n",
      "Label ids (should strip BOS token): \n",
      "tensor([[ 4191,  8001,    14,  3963,  3783,  4043, 15463,  4835,    71,    16,\n",
      "             2]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Special token ids: Padding - 0, EOS - 1, BOS - 2\")\n",
    "\n",
    "batch_num = 0\n",
    "for batch in de_en_train_dataloader:\n",
    "    batch_num += 1\n",
    "\n",
    "    print(\"\\nBatch: \", batch_num)\n",
    "    print(\"Encoder input ids: \")\n",
    "    print(batch['encoder_input_ids'])\n",
    "\n",
    "    print(\"\\nDecoder input ids (should strip EOS token): \")\n",
    "    print(batch['decoder_input_ids'])\n",
    "\n",
    "    print(\"\\nLabel ids (should strip BOS token): \")\n",
    "    print(batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f226d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dnlp2025.download_datasets import download_wmt14_de_en\n",
    "\n",
    "de_en_dataset = download_wmt14_de_en()\n",
    "small_dataset = de_en_dataset['train'].train_test_split(train_size=0.1, seed=42)['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d892d499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ec7a69e91643fe82c37d286653aa38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing dataset (num_proc=10):   0%|          | 0/450878 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartekryba/Library/Caches/pypoetry/virtualenvs/dnlp2025-V-ztQv5h-py3.12/lib/python3.12/site-packages/torch/utils/data/sampler.py:68: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "de_en_full_dataloader = dnlp2025.dataset.create_dataloader(\n",
    "    small_dataset,\n",
    "    \"train\",\n",
    "    de_en_tokenizer,\n",
    "    max_tokens_per_batch=25000,\n",
    "    shuffle=True,\n",
    "    num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf0172a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_en_full_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86115086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoder_input_ids': tensor([[    1, 15607,  4712,  ...,  3923,  9944,     2],\n",
      "        [    1,  4004,  3964,  ...,  9139,    16,     2],\n",
      "        [    1,  4863,  3772,  ..., 13443,    16,     2],\n",
      "        ...,\n",
      "        [    1,  3885,  5077,  ...,  8689,    16,     2],\n",
      "        [    1,  3885,  9889,  ...,  3923,    16,     2],\n",
      "        [    1,    40,  3892,  ..., 28280,    16,     2]]), 'decoder_input_ids': tensor([[    1,  9495,  9542,  ...,     0,     0,     0],\n",
      "        [    1, 10390, 19170,  ...,     0,     0,     0],\n",
      "        [    1,  3869, 18639,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  4275,  4095,  ...,     0,     0,     0],\n",
      "        [    1,  4275, 12688,  ...,     0,     0,     0],\n",
      "        [    1, 12772,  5274,  ...,     0,     0,     0]]), 'labels': tensor([[ 9495,  9542,    16,  ...,     0,     0,     0],\n",
      "        [10390, 19170,    14,  ...,     0,     0,     0],\n",
      "        [ 3869, 18639,  5862,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 4275,  4095,  5039,  ...,     0,     0,     0],\n",
      "        [ 4275, 12688, 21908,  ...,     0,     0,     0],\n",
      "        [12772,  5274,  3939,  ...,     0,     0,     0]]), 'src_key_padding_mask': tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), 'tgt_key_padding_mask': tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]]), 'tgt_mask': tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in de_en_full_dataloader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
